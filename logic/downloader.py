import subprocess
import os
import re
import signal
import time
from urllib.parse import urlparse
import psutil
import requests
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import json
from urllib.parse import parse_qs, unquote
env = os.environ.copy()
env["PYTHONIOENCODING"] = "utf-8"

CREATE_NO_WINDOW = 0x08000000

def is_youtube(url):
    netloc = urlparse(url).netloc
    return "youtube.com" in netloc or "youtu.be" in netloc

def kill_proc_tree(pid):
    try:
        parent = psutil.Process(pid)
        for child in parent.children(recursive=True):
            child.kill()
        parent.kill()
    except Exception as e:
        print(f"âŒ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹¤íŒ¨: {e}")

def get_channel_name_from_url(url):
    try:
        import yt_dlp
        info = yt_dlp.YoutubeDL().extract_info(url, download=False)
        return info.get("channel").replace("/", "_")
    except:
        return "unknown_channel"

def run_ytdlp(url, output_path, filename, log_func, resolution="720", audio_only=False, cancel_check_func=lambda: False):
    log_func(f"â–¶ yt-dlp ì‹¤í–‰: {url}")
    try:
        ffmpeg_path = os.path.abspath(os.path.join("ffmpeg", "ffmpeg.exe"))
        channel_name = get_channel_name_from_url(url)
        channel_name = re.sub(r'[\\\\/:*?\"<>|]', '', channel_name)  # sanitize
        youtube_output_path = os.path.join(output_path, "youtube", channel_name)

        if filename:
            filename = re.sub(r'[\\/:*?\"<>|]', '', filename)
            output_template = f"{filename}.%(ext)s"
            filename_base = filename
        else:
            output_template = "%(title)s.%(ext)s"
            filename_base = None

        command = ["yt-dlp", url, "-P", youtube_output_path, "--no-playlist", "--no-part", "-o", output_template]

        if audio_only:
            command += [
                "-x", "--audio-format", "mp3",
                "--audio-quality", "320k",
                "--ffmpeg-location", ffmpeg_path
            ]
        else:
            command += [
                "-f", f"bestvideo[height<={resolution}]+bestaudio/best",
                "--remux-video", "mp4",
                "--ffmpeg-location", ffmpeg_path
            ]

        proc = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True,
            encoding='utf-8',
            errors='replace',
            creationflags=CREATE_NO_WINDOW | (subprocess.CREATE_NEW_PROCESS_GROUP if os.name == "nt" else 0),
            env=env
        )

        while proc.poll() is None:
            if cancel_check_func():
                log_func("â›” ì·¨ì†Œ ê°ì§€ â†’ yt-dlp ì¤‘ë‹¨ ë° ì„ì‹œ íŒŒì¼ ì‚­ì œ")
                kill_proc_tree(proc.pid)
                if filename_base:
                    cleanup_ytdlp_files(youtube_output_path, filename_base, log_func)
                else:
                    cleanup_ytdlp_temp_files(youtube_output_path, log_func)
                return False

            line = proc.stdout.readline()
            if line:
                log_func(line.strip())

        return proc.returncode == 0

    except Exception as e:
        log_func(f"âŒ yt-dlp ì˜¤ë¥˜: {e}")
        return False

def scroll_to_bottom(driver, log_func, pause_time=2, max_tries=20):
    last_height = driver.execute_script("return document.documentElement.scrollHeight")
    tries = 0
    while tries < max_tries:
        log_func(f"ğŸ”„ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘... (ì‹œë„ {tries + 1}/{max_tries})")
        driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
        time.sleep(pause_time)
        new_height = driver.execute_script("return document.documentElement.scrollHeight")
        if new_height == last_height:
            tries += 1
        else:
            tries = 0
            last_height = new_height
    log_func("âœ… ìŠ¤í¬ë¡¤ ì™„ë£Œ, ëª¨ë“  ê²Œì‹œê¸€ ë¡œë”© ì™„ë£Œ")

def extract_channel_id(url):
    """URLì—ì„œ ì±„ë„ IDë¥¼ ì¶”ì¶œ"""
    try:
        from urllib.parse import unquote
        # URL ë””ì½”ë”©
        decoded_url = unquote(url)
        
        if '@' in decoded_url:
            # @username í˜•ì‹ì˜ URL
            channel_id = decoded_url.split('/community')[0].split('@')[-1]
        else:
            # ì±„ë„ ID í˜•ì‹ì˜ URL
            channel_id = decoded_url.split('/channel/')[-1].split('/')[0]
        
        return channel_id
    except:
        return None

def get_community_posts(channel_id, log_func=print):
    """ì±„ë„ì˜ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œë¬¼ì„ ê°€ì ¸ì˜´"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': '*/*',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7,ja;q=0.6',
        'Origin': 'https://www.youtube.com',
        'Referer': 'https://www.youtube.com/'
    }

    try:
        # ì±„ë„ í˜ì´ì§€ URL ìƒì„± (ì¸ì½”ë”©ëœ ìƒíƒœ ìœ ì§€)
        url = f'https://www.youtube.com/@{channel_id}/community'
        
        # ì²« ë²ˆì§¸ ì‹œë„
        response = requests.get(url, headers=headers)
        
        # 404 ì—ëŸ¬ì‹œ ë‹¤ì‹œ ì‹œë„
        if response.status_code == 404:
            # URL ì¸ì½”ë”©í•˜ì—¬ ë‹¤ì‹œ ì‹œë„
            from urllib.parse import quote
            encoded_channel_id = quote(channel_id)
            url = f'https://www.youtube.com/@{encoded_channel_id}/community'
            response = requests.get(url, headers=headers)
        
        if response.status_code != 200:
            log_func(f"âŒ ì±„ë„ í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: HTTP {response.status_code}")
            return None

        # ytInitialDataë¥¼ ì¶”ì¶œ
        html = response.text
        data_match = re.search(r'var ytInitialData = ({.*?});', html)
        if not data_match:
            # ë‹¤ë¥¸ íŒ¨í„´ìœ¼ë¡œ ì‹œë„
            data_match = re.search(r'ytInitialData\s*=\s*({.*?});', html)
            if not data_match:
                log_func("âŒ ì±„ë„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

        data = json.loads(data_match.group(1))
        
        # ì±„ë„ ì´ë¦„ ì¶”ì¶œ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
        try:
            if 'header' in data and 'c4TabbedHeaderRenderer' in data['header']:
                channel_name = data['header']['c4TabbedHeaderRenderer']['title']
            elif 'metadata' in data and 'channelMetadataRenderer' in data['metadata']:
                channel_name = data['metadata']['channelMetadataRenderer']['title']
            else:
                channel_name = channel_id
        except:
            channel_name = channel_id
            
        # ì»¤ë®¤ë‹ˆí‹° íƒ­ì˜ ê²Œì‹œë¬¼ ì¶”ì¶œ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
        try:
            items = data['contents']['twoColumnBrowseResultsRenderer']['tabs']
            community_tab = next(tab for tab in items if tab.get('tabRenderer', {}).get('title') == 'Community')
            posts = community_tab['tabRenderer']['content']['sectionListRenderer']['contents'][0]['itemSectionRenderer']['contents']
        except:
            try:
                # ëŒ€ì²´ ê²½ë¡œ ì‹œë„
                posts = data['contents']['twoColumnBrowseResultsRenderer']['tabs'][1]['tabRenderer']['content']['sectionListRenderer']['contents']
            except:
                log_func("âŒ ì»¤ë®¤ë‹ˆí‹° ê²Œì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

        return channel_name, posts
    except Exception as e:
        log_func(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def crawl_community_images_with_id(url, output_dir, log_func=print, cancel_check=lambda: False):
    log_func("ğŸ” ìœ íŠœë¸Œ ì»¤ë®¤ë‹ˆí‹° ì´ë¯¸ì§€ í¬ë¡¤ë§ ì‹œì‘...")

    try:
        # URL ë””ì½”ë”© (ë” ì¼ì° ìˆ˜í–‰)
        decoded_url = unquote(url)
        if decoded_url != url:
            log_func(f"ğŸ”— URL ë””ì½”ë”©: {url}")
            log_func(f"ğŸ”— ë””ì½”ë”©ëœ URL: {decoded_url}")

        # Chrome ì˜µì…˜ ì„¤ì •
        options = Options()
        options.add_argument("--headless")
        options.add_argument("--disable-gpu")
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)

        # í¬ë¡¬ ë“œë¼ì´ë²„ ìë™ ì„¤ì¹˜ ë° ì‹¤í–‰
        log_func("ğŸ”„ í¬ë¡¬ ë“œë¼ì´ë²„ ì¤€ë¹„ ì¤‘...")
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
            "source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined});"
        })

        log_func("ğŸŒ í˜ì´ì§€ ì—´ê¸° ì¤‘...")
        driver.get(decoded_url)
        time.sleep(2)

        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "ytd-backstage-post-renderer"))
            )
        except:
            log_func("âš ï¸ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼, ê³„ì† ì§„í–‰...")

        log_func("ğŸ“œ ì „ì²´ í˜ì´ì§€ ë¡œë”© ë° ìŠ¤í¬ë¡¤ ì‹œì‘")
        scroll_to_bottom(driver, log_func)

        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')

        # URLì—ì„œ ì±„ë„ëª… ì¶”ì¶œ ì‹œë„
        channel_name = None
        if '@' in decoded_url:
            channel_name = decoded_url.split('@')[1].split('/')[0]
            log_func(f"ğŸ“º ì±„ë„ëª… ì¶”ì¶œ: {channel_name}")
        else:
            # ì±„ë„ëª… ì¶”ì¶œ ì‹œë„ (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
            channel_name_elem = soup.select_one("ytd-channel-name yt-formatted-string#text")
            if not channel_name_elem:
                channel_name_elem = soup.select_one("ytd-channel-name yt-formatted-string")
            if not channel_name_elem:
                channel_name_elem = soup.select_one("yt-formatted-string.ytd-channel-name")
            
            if channel_name_elem:
                channel_name = channel_name_elem.get_text(strip=True)
                log_func(f"ğŸ“º ì±„ë„ëª… ì¶”ì¶œ: {channel_name}")
        
        if not channel_name:
            channel_name = "unknown_channel"
            log_func("âš ï¸ ì±„ë„ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ 'unknown_channel'ë¡œ ì„¤ì •")
            
        # ì±„ë„ëª… ì •ë¦¬
        original_channel_name = channel_name
        channel_name = channel_name.replace("/", "_")
        channel_name = re.sub(r'[\\/:*?"<>|]', '_', channel_name)  # íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        
        if original_channel_name != channel_name:
            log_func(f"ğŸ“ ì±„ë„ëª… ì •ë¦¬: {original_channel_name} â†’ {channel_name}")
        
        # ì €ì¥ ê²½ë¡œ ì„¤ì •: youtube/ì±„ë„ëª…
        youtube_dir = os.path.join(output_dir, "youtube")
        os.makedirs(youtube_dir, exist_ok=True)
        channel_dir = os.path.join(youtube_dir, channel_name)
        os.makedirs(channel_dir, exist_ok=True)
        log_func(f"ğŸ“ ì €ì¥ ê²½ë¡œ ìƒì„±: {channel_dir}")

        driver.quit()

        # ëª¨ë“  ê²Œì‹œê¸€ì„ ì—­ìˆœìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        posts = list(reversed(soup.select("ytd-backstage-post-renderer")))
        log_func(f"ğŸ“¦ ì´ ê²Œì‹œê¸€ ìˆ˜: {len(posts)}")
        success = 0
        fail = 0
        image_counter = 1

        for post in posts:
            if cancel_check():
                log_func("â›” ì‘ì—… ì·¨ì†Œ ìš”ì²­ë¨ â†’ í¬ë¡¤ë§ ì¤‘ë‹¨")
                break

            imgs = post.find_all("img")
            for img in imgs:
                src = img.get("src")
                if not src:
                    continue
                
                log_func(f"[DEBUG] ì´ë¯¸ì§€ src: {src}")

                if "yt3.ggpht.com" in src or "ytimg.com" in src:
                    # ê³ í•´ìƒë„ URLë¡œ ë³€í™˜
                    highres_src = src.split('=')[0] + "=s2048"
                    filename = f"{image_counter}.jpg"
                    filepath = os.path.join(channel_dir, filename)
                    
                    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ ê±´ë„ˆë›°ê¸°
                    if os.path.exists(filepath):
                        log_func(f"âš ï¸ Skip: {filename} (ì´ë¯¸ ì¡´ì¬í•¨)")
                        continue

                    try:
                        r = requests.get(highres_src, timeout=10)
                        if r.status_code == 200:
                            with open(filepath, "wb") as f:
                                f.write(r.content)
                            log_func(f"âœ… Saved: {filename}")
                            success += 1
                            image_counter += 1
                        else:
                            log_func(f"âŒ Skipped: HTTP {r.status_code} â†’ {filename}")
                            fail += 1
                    except Exception as e:
                        log_func(f"âŒ Failed: {e}")
                        fail += 1

        log_func(f"\nğŸ¯ ìµœì¢… ê²°ê³¼: ì„±ê³µ {success}ê°œ, ì‹¤íŒ¨ {fail}ê°œ")
        return channel_dir if success > 0 else None

    except Exception as e:
        log_func(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        if 'driver' in locals():
            driver.quit()
        return None

def smart_download(url, output_dir, filename, log_func, resolution="720", audio_only=False, cancel_check_func=lambda: False):
    try:
        import yt_dlp
    except ImportError:
        log_func("âŒ yt-dlp ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

    if "/community" in url:
        # ì»¤ë®¤ë‹ˆí‹° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„
        result = crawl_community_images_with_id(
            url, output_dir, log_func=log_func, cancel_check=cancel_check_func
        )
        # resultê°€ Noneì´ ì•„ë‹ˆë©´ ì„±ê³µì ìœ¼ë¡œ ì±„ë„ ë””ë ‰í† ë¦¬ê°€ ìƒì„±ëœ ê²ƒ
        return result is not None and not cancel_check_func()

    if is_youtube(url):
        return run_ytdlp(
            url=url,
            output_path=output_dir,
            filename=filename,
            log_func=log_func,
            resolution=resolution,
            audio_only=audio_only,
            cancel_check_func=cancel_check_func
        )
    return None

def cleanup_ytdlp_temp_files(download_dir, log_func, window_seconds=300):
    try:
        now = time.time()
        exts = [".webm", ".mp4", ".mkv", ".m4a", ".part", ".temp"]
        deleted = 0

        for file in os.listdir(download_dir):
            path = os.path.join(download_dir, file)
            if not os.path.isfile(path):
                continue

            is_target_ext = any(file.endswith(ext) for ext in exts)
            is_temp_name = re.search(r"\.f\d{3,4}\.", file)
            is_recent = now - os.path.getmtime(path) < window_seconds

            if is_target_ext and (is_recent or is_temp_name):
                os.remove(path)
                log_func(f"ğŸ§¹ yt-dlp ì„ì‹œ/ì¤‘ê°„ íŒŒì¼ ì‚­ì œë¨: {path}")
                deleted += 1

        if deleted == 0:
            log_func("â„¹ï¸ ì‚­ì œëœ yt-dlp ì„ì‹œ íŒŒì¼ ì—†ìŒ")
    except Exception as e:
        log_func(f"âš ï¸ yt-dlp íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

def download_gallery(url, output_dir, filename, selected_exts, log_func, status_func, cancel_check_func, proc_register):
    try:
        command = ["gallery-dl", "-d", output_dir]
        if selected_exts:
            ext_list_str = ", ".join(f"'{ext}'" for ext in selected_exts)
            command += ["--filter", f"extension in ({ext_list_str})"]

            if len(selected_exts) == 1 and 'zip' in selected_exts:
                if filename:
                    command += ["-o", f"filename={filename}_{{filename}}.{{extension}}"]
            else:
                if filename:
                    command += ["-o", f"filename={filename}_{{num}}.{{extension}}"]

        command.append(url)
        log_func(f"ëª…ë ¹ì–´ ì‹¤í–‰: {' '.join(command)}")

        proc = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True,
            encoding='utf-8',
            errors='replace',
            creationflags=CREATE_NO_WINDOW | (subprocess.CREATE_NEW_PROCESS_GROUP if os.name == "nt" else 0),
            env=env
        )
        proc_register(proc)

        downloaded = 0
        total_guess = 30

        while proc.poll() is None:
            if cancel_check_func():
                log_func("â›” ì·¨ì†Œ ê°ì§€ë¨ â†’ í”„ë¡œì„¸ìŠ¤ íŠ¸ë¦¬ ê°•ì œ ì¢…ë£Œ")
                kill_proc_tree(proc.pid)
                return False

            line = proc.stdout.readline()
            if line:
                line = line.strip()
                log_func(line)
                
                if "[download]" in line:
                    downloaded += 1
                    percent = min(int((downloaded / total_guess) * 100), 100)
                    status_func(f"ìƒíƒœ: ë‹¤ìš´ë¡œë“œ ì¤‘... {percent}%")

        if proc.returncode == 0:
            status_func("ìƒíƒœ: ì™„ë£Œ")
            log_func("âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            return True
        else:
            status_func("ìƒíƒœ: ì˜¤ë¥˜")
            log_func(f"âŒ gallery-dl ì—ëŸ¬ ì½”ë“œ: {proc.returncode}")
            return False

    except Exception as e:
        log_func(f"âŒ gallery-dl ì˜¤ë¥˜ ë°œìƒ: {e}")
        status_func("ìƒíƒœ: ì‹¤íŒ¨")
        return False